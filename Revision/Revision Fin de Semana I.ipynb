{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Revision Fin de Semana I.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/antoniosql/cursoml/blob/master/Laboratorio_03_Analizando_los_datos_del_Titanic_Solucion_limpia%20v2.ipynb","timestamp":1560071009203}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"y2h3h-iIIlRz","colab_type":"text"},"source":["![SolidQ](https://www.solidq.com/wp-content/uploads/2015/06/Logo-SolidQ-Web.gif)\n","# Revisión Fin de Semana I\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BI9hpKBoIlR2","colab_type":"text"},"source":["### Cargando el conjunto de datos y obteniendo información básica:\n","El objetivo de esta sección es que nos familiarizemos con Pandas y seamos capaces de manipular el dataset a nuestro interés.\n","\n","utilizaremos para este caso el fichero titanic_data.csv"]},{"cell_type":"code","metadata":{"id":"G8Ly3MHvIlR4","colab_type":"code","colab":{}},"source":["import pandas\n","import numpy as np\n","\n","\n","input_file = 'titanic_data.csv'\n","separador = \",\"\n","dataset = pandas.read_csv(filepath_or_buffer=input_file, sep=separador)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7NBqkrG3k_Dy","colab_type":"text"},"source":["# Creando el Modelo\n","\n","En esta seción vamos a trabajar en la creación de un modelo que sirva para determinar si un pasajero va a sobrevivir o no. Lo primero que haremos será crear nuestro propio modelo en función de las conclusiones que hemos sacado, y después lo compararemos con un árbol de decision que entrenaremos con el dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"ERB0IvaFjNrh","colab_type":"code","colab":{}},"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmxq0BLdj0VG","colab_type":"code","colab":{}},"source":["# 'Survived' será nuestra etiqueta y el valor que queremos predecir:\n","y = dataset['Survived']\n","X = dataset.drop(['Survived','Name','Ticket','Cabin','PassengerId','SibSp','Parch'], axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R1jr4XKKo5NI","colab_type":"code","colab":{}},"source":["X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3, random_state = 0,stratify=y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VVHdXSLi_jo","colab_type":"code","colab":{}},"source":["#Vamos a definir un Pipeline que nos permita realizar las tareas de limpieza y transformación sobre varias columnas\n","\n","#Seleccionamos las caolumnas numéricas\n","numeric_features = ['Age', 'Fare']\n","#Definimos las transformaciones que les vamos a aplicar --> Imputar nulos y escalar\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler())])\n","\n","#Definimos las variables categóricas y las trnasformaciones --> Imputar con 'missing' y aplicar una Codificación OneHot\n","\n","categorical_features = ['Embarked', 'Sex', 'Pclass']\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","#Utilizamos el método ColumnTransformer para asociar los pipelines a las columnas\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)])\n","\n","# Agregamos un clasificador de Regresión Logística\n","# Ahora tenemos el Pipeline completo\n","\n","clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', DecisionTreeClassifier(max_depth=4))])\n","\n","\n","\n","\n","clf.fit(X_train, y_train)\n","\n","#OJO, aquí no estamos cambiando nuestro dataset original. Simplemente lanzamos este pipeline que realiza las transformaciones \"al vuelo\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICyVlcygHm9N","colab_type":"code","colab":{}},"source":["\n","\n","# Crear predicciones\n","predictions = clf.predict(X_test)\n","\n","predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iq1MUftOtSQN","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(confusion_matrix(y_test, predictions))\n","print(classification_report(y_test, predictions))"],"execution_count":0,"outputs":[]}]}