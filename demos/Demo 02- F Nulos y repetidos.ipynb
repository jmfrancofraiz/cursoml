{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Demo 02- F Nulos y repetidos.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["dMo5pS1De55q"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"dMo5pS1De55q","colab_type":"text"},"cell_type":"markdown","source":["# Getionando valores nulos"]},{"metadata":{"id":"fyXux7KEe9XO","colab_type":"code","outputId":"2e8e9e6d-f16f-4e3e-9ea2-1fe565240885","executionInfo":{"status":"ok","timestamp":1550225130593,"user_tz":-60,"elapsed":553,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"cell_type":"code","source":["import pandas as pd\n","from io import StringIO\n","csv_data = \\\n","  '''A,B,C,D\n","  1.0,2.0,3.0,4.0\n","  5.0,6.0,,8.0\n","  10.0,11.0,12.0,'''\n","# If you are using Python 2.7, you need\n","# to convert the string to unicode:\n","# csv_data = unicode(csv_data)\n","df = pd.read_csv(StringIO(csv_data))\n","df\n","#Using the preceding code, we read CSV-formatted data into a pandas DataFrame via the read_csv function and noticed that the two missing cells were replaced by NaN. \n","#The StringIO function in the preceding code example was simply used for the\n","#purposes of illustration. It allows us to read the string assigned to csv_data into a pandas DataFrame as if it was a regular CSV file on our hard drive."],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      A     B     C    D\n","0   1.0   2.0   3.0  4.0\n","1   5.0   6.0   NaN  8.0\n","2  10.0  11.0  12.0  NaN"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"fJ89fmgxhJrN","colab_type":"code","outputId":"0b59148e-5e42-48a3-bd6c-0bfb4a3cf453","executionInfo":{"status":"ok","timestamp":1550223461001,"user_tz":-60,"elapsed":576,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"cell_type":"code","source":["df.isna().sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["A    0\n","B    0\n","C    1\n","D    1\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"o6MZdmuRha5R","colab_type":"code","outputId":"765da270-6b6b-472e-bd77-300271028ee9","executionInfo":{"status":"ok","timestamp":1550223532447,"user_tz":-60,"elapsed":561,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["#acceso al array NumPy que tenemos por detrás\n","df.values"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.,  2.,  3.,  4.],\n","       [ 5.,  6., nan,  8.],\n","       [10., 11., 12., nan]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"L1YS8H6RhkE4","colab_type":"code","outputId":"2b001bfe-b76d-4417-8e7d-ecb4bcdfc096","executionInfo":{"status":"ok","timestamp":1550223570328,"user_tz":-60,"elapsed":583,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":79}},"cell_type":"code","source":["#lo más \"fácil\"\n","df.dropna(axis=0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     A    B    C    D\n","0  1.0  2.0  3.0  4.0"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"SBNkL6Brhrft","colab_type":"code","outputId":"d72b75ec-8f44-467d-ec31-3c05e6eb77e9","executionInfo":{"status":"ok","timestamp":1550223595499,"user_tz":-60,"elapsed":562,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"cell_type":"code","source":["#también podemos borrar columnas\n","df.dropna(axis=1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      A     B\n","0   1.0   2.0\n","1   5.0   6.0\n","2  10.0  11.0"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"60C8cl-9hzet","colab_type":"code","colab":{}},"cell_type":"code","source":["#borrar filas donde todos los valores sea NaN\n","df.dropna(how='all')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ztTWDBFPh8Ym","colab_type":"code","colab":{}},"cell_type":"code","source":["#borrar filas que tienen menos de 4 valores reales\n","df.dropna(thresh=4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-T-d8OJciE_X","colab_type":"code","outputId":"ad7cd038-01c3-4d82-f0bb-edd1d4fc1db5","executionInfo":{"status":"ok","timestamp":1550223702790,"user_tz":-60,"elapsed":579,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":111}},"cell_type":"code","source":["#borrar filas con NaN en una columna específica\n","df.dropna(subset=['C'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      A     B     C    D\n","0   1.0   2.0   3.0  4.0\n","2  10.0  11.0  12.0  NaN"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"M3Rd4QD9nhu8","colab_type":"code","outputId":"5845fa26-6559-41b3-92e5-52b71ed41a30","executionInfo":{"status":"ok","timestamp":1550225139335,"user_tz":-60,"elapsed":576,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["#directamente el porcentaje de valores nulos\n","# https://www.dunderdata.com/post/finding-the-percentage-of-missing-values-in-a-pandas-dataframe \n","df.isna().mean().round(4) * 100"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["A     0.00\n","B     0.00\n","C    33.33\n","D    33.33\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"QiGq72puicjc","colab_type":"text"},"cell_type":"markdown","source":["Often, the removal of samples or dropping of entire feature columns is simply not\n","feasible, because we might lose too much valuable data. In this case, we can use\n","different interpolation techniques to estimate the missing values from the other\n","training samples in our dataset. One of the most common interpolation techniques\n","is mean imputation, where we simply replace the missing value with the mean\n","value of the entire feature column. A convenient way to achieve this is by using the\n","Imputer class from scikit-learn, as shown in the following code"]},{"metadata":{"id":"vymd7NHlibdA","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.preprocessing import Imputer\n","imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n","imr = imr.fit(df.values)\n","imputed_data = imr.transform(df.values)\n","imputed_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U6mvYYdlkGWy","colab_type":"text"},"cell_type":"markdown","source":["Here, we replaced each NaN value with the corresponding mean, which is separately\n","calculated for each feature column. If we changed the axis=0 setting to axis=1, we'd\n","calculate the row means. Other options for the strategy parameter are median or\n","most_frequent, where the latter replaces the missing values with the most frequent\n","values. This is useful for imputing categorical feature values, for example, a feature\n","column that stores an encoding of color names, such as red, green, and blue, and we\n","will encounter examples of such data later in this chapter."]},{"metadata":{"id":"o-k8OYEmjrvM","colab_type":"code","outputId":"8cd9eb35-a0bb-4733-f77a-30e5cd252631","executionInfo":{"status":"ok","timestamp":1550224150069,"user_tz":-60,"elapsed":515,"user":{"displayName":"Antonio Soto","photoUrl":"","userId":"01816434250299075148"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","my_imputer = SimpleImputer()\n","imputed_data = pd.DataFrame(my_imputer.fit_transform(df))\n","imputed_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>7.5</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10.0</td>\n","      <td>11.0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0     1     2    3\n","0   1.0   2.0   3.0  4.0\n","1   5.0   6.0   7.5  8.0\n","2  10.0  11.0  12.0  6.0"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"45fwU6ZagBH2","colab_type":"text"},"cell_type":"markdown","source":["# Valores duplicados"]},{"metadata":{"id":"cicomAMMpaU0","colab_type":"code","colab":{}},"cell_type":"code","source":["# import pandas as pd\n","import numpy as np\n"," \n","#Create a DataFrame\n","d = {\n","    'Name':['Alisa','Bobby','jodha','jack','raghu','Cathrine',\n","            'Alisa','Bobby','kumar','Alisa','Alex','Cathrine'],\n","    'Age':[26,24,23,22,23,24,26,24,22,23,24,24],\n","      \n","       'Score':[85,63,55,74,31,77,85,63,42,62,89,77]}\n"," \n","df = pd.DataFrame(d,columns=['Name','Age','Score'])\n","df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PbN_9pw2peNz","colab_type":"code","colab":{}},"cell_type":"code","source":["df[\"is_duplicate\"]= df.duplicated()\n"," \n","df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"alY9snUkpmkl","colab_type":"code","colab":{}},"cell_type":"code","source":["# drop duplicate rows\n"," \n","df.drop_duplicates()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qiqT8GF5pp4s","colab_type":"code","colab":{}},"cell_type":"code","source":["# drop duplicate rows\n"," \n","df.drop_duplicates(keep='last')\n","#In the above example keep=’last’ argument . Keeps the last duplicate row and delete the rest duplicated rows. So the output will be"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D502sj9npt6x","colab_type":"code","colab":{}},"cell_type":"code","source":["# Now let’s drop the rows by column name. Rows are dropped in such a way that unique column value is retained for that column as shown below\n","# drop duplicate by a column name\n"," \n","df.drop_duplicates(['Name'], keep='last')\n","\n","#In the above example rows are deleted in such a way that, Name column contains only unique values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H5wZiyFmrEHp","colab_type":"text"},"cell_type":"markdown","source":["Más ejemplos: https://nbviewer.jupyter.org/github/pydata/pydata-book/blob/2nd-edition/ch07.ipynb "]}]}