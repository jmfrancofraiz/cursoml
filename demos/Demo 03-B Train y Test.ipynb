{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Demo 03- B Train y Test.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JoHf1DL1wBMB","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',header=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbiN03j-wNWl","colab_type":"code","colab":{}},"source":["df_wine.columns = ['Class label', 'Alcohol',\n","  'Malic acid', 'Ash',\n","  'Alcalinity of ash', 'Magnesium',\n","  'Total phenols', 'Flavanoids',\n","  'Nonflavanoid phenols',\n","  'Proanthocyanins',\n","  'Color intensity', 'Hue',\n","  'OD280/OD315 of diluted wines',\n","  'Proline']\n","print('Class labels', np.unique(df_wine['Class label']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3Vl4ZUSwkWj","colab_type":"code","colab":{}},"source":["df_wine.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8fJ7uQRiwqPL","colab_type":"text"},"source":["En esta caso tenemos uvas de tres clases diferentes 1, 2 y 3 "]},{"cell_type":"code","metadata":{"id":"MNpwWMokwrK8","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n","X_train, X_test, y_train, y_test =\\\n","  train_test_split(X, y,\n","  test_size=0.3,\n","  random_state=0,\n","  stratify=y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0uUYizTkw7Ny","colab_type":"text"},"source":["Primero, asignamos la representación en array NumPy de las columnas de características a la variable X. Asignamos las clases de la primera columna a la variable y. Después, utilizamos la función train_test_split para separar en conjuntos de datos de entrenamiento y prueba de forma aleatoria. En este caso estamos asignando el 30% a test y el 70% al conjunto de entrenamiento. El objetivo de pasar también el array de la etiqueta (y) como argumento nos asegura que ambos conjuntos de datos tienen las mismas proporcionas de valores de esa clase que el dataset original"]},{"cell_type":"markdown","metadata":{"id":"RyE0pE9Qw8O6","colab_type":"text"},"source":["Si dividimos un conjunto de datos en datos de entrenamiento y pruebas debemos de ser conscientes de que estamos dejando de pasarle al algoritmo información que puede ser valiosa, por lo que no debemos de asignar un porcentaje demasiado elevado a ese conjunto de datos. Sin embargo, cuando más pequeño sea el conjunto de entrenamiento, más imprecisa es la estimación del error de generalización. Dividir un conjunto de datos en entrenamiento y prueba se trata de balancear estos dos escenarios. Lo más común es 60:$0, 70·30 o 80:20. Sin embargo para conjuntos de datos muy grandes no es rato ver ratios como 90:10 o incluso 99:1\n"]}]}