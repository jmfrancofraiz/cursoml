{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo 03 G Evaluacion de Modelos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniosql/cursoml/blob/master/demos/Demo_03_G_Evaluacion_de_Modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lk4f-SobIwPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "  \n",
        "---"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "1K5ZLFUVIwPJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluación de Modelos"
      ]
    },
    {
      "metadata": {
        "id": "bcQP0a1rIwPL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluación para Clasificación"
      ]
    },
    {
      "metadata": {
        "id": "8wJorKnhIwPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cargamos y preparamos los datos"
      ]
    },
    {
      "metadata": {
        "id": "0IQ8fVt7IwPN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%matplotlib notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "dataset = load_digits()\n",
        "X, y = dataset.data, dataset.target\n",
        "\n",
        "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
        "    print(class_name,class_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axY1sF3WIwPT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating a dataset with imbalanced binary classes:  \n",
        "# Negative class (0) is 'not digit 1' \n",
        "# Positive class (1) is 'digit 1'\n",
        "y_binary_imbalanced = y.copy()\n",
        "y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
        "\n",
        "print('Original labels:\\t', y[1:30])\n",
        "print('New binary labels:\\t', y_binary_imbalanced[1:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "tckEdqTqIwPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.bincount(y_binary_imbalanced)    # Negative class (0) is the most frequent class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCFaici2IwPb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "\n",
        "# Accuracy of Support Vector Machine classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
        "svm.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4YNF5NlIwPe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Clasificador Dummy"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "rdD5CcuCIwPg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DummyClassifier is a classifier that makes predictions using simple rules, which can be useful as a baseline for comparison against actual classifiers, especially with imbalanced classes."
      ]
    },
    {
      "metadata": {
        "id": "8Xg_2wXUIwPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# Negative class (0) is most frequent\n",
        "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "# Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
        "y_dummy_predictions = dummy_majority.predict(X_test)\n",
        "\n",
        "y_dummy_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4pQbW2-7IwPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dummy_majority.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nITfaQOIwPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "svm.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O1qcebLIwPv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matrice de Confusion "
      ]
    },
    {
      "metadata": {
        "id": "-FtvzwoEIwPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Binary (two-class) confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "otJ43sB8IwP0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Negative class (0) is most frequent\n",
        "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "y_majority_predicted = dummy_majority.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_majority_predicted)\n",
        "\n",
        "print('Most frequent class (dummy classifier)\\n', confusion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtVdah-DIwP5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# produces random predictions w/ same class proportion as training set\n",
        "dummy_classprop = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
        "y_classprop_predicted = dummy_classprop.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_classprop_predicted)\n",
        "\n",
        "print('Random class-proportional prediction (dummy classifier)\\n', confusion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "K1aSszUNIwP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "svm_predicted = svm.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, svm_predicted)\n",
        "\n",
        "print('Support vector machine classifier (linear kernel, C=1)\\n', confusion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueoV9vNYIwQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression().fit(X_train, y_train)\n",
        "lr_predicted = lr.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, lr_predicted)\n",
        "\n",
        "print('Logistic regression classifier (default settings)\\n', confusion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GgS7mXrIwQE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
        "tree_predicted = dt.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, tree_predicted)\n",
        "\n",
        "print('Decision tree classifier (max_depth = 2)\\n', confusion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fDzof5XDIwQK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Métricas de Evaluación para clasificación binaria"
      ]
    },
    {
      "metadata": {
        "id": "4gWzWuUZIwQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
        "# Precision = TP / (TP + FP)\n",
        "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
        "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
        "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, tree_predicted)))\n",
        "print('Precision: {:.2f}'.format(precision_score(y_test, tree_predicted)))\n",
        "print('Recall: {:.2f}'.format(recall_score(y_test, tree_predicted)))\n",
        "print('F1: {:.2f}'.format(f1_score(y_test, tree_predicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6qVIyn3vIwQO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Combined report with all above metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, tree_predicted, target_names=['not 1', '1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "rGYSGFm1IwQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Random class-proportional (dummy)\\n', \n",
        "      classification_report(y_test, y_classprop_predicted, target_names=['not 1', '1']))\n",
        "print('SVM\\n', \n",
        "      classification_report(y_test, svm_predicted, target_names = ['not 1', '1']))\n",
        "print('Logistic regression\\n', \n",
        "      classification_report(y_test, lr_predicted, target_names = ['not 1', '1']))\n",
        "print('Decision tree\\n', \n",
        "      classification_report(y_test, tree_predicted, target_names = ['not 1', '1']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qh_9P79mIwQa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Funciones de decisión"
      ]
    },
    {
      "metadata": {
        "id": "pLJ_wYwtIwQd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "y_scores_lr = lr.fit(X_train, y_train).decision_function(X_test)\n",
        "y_score_list = list(zip(y_test[0:20], y_scores_lr[0:20]))\n",
        "\n",
        "# show the decision_function scores for first 20 instances\n",
        "y_score_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbNICdonIwQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "y_proba_lr = lr.fit(X_train, y_train).predict_proba(X_test)\n",
        "y_proba_list = list(zip(y_test[0:20], y_proba_lr[0:20,1]))\n",
        "\n",
        "# show the probability of positive class for first 20 instances\n",
        "y_proba_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkXrLSXNIwQp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Curvas de precisión Re-call"
      ]
    },
    {
      "metadata": {
        "id": "W0E84OyiIwQq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores_lr)\n",
        "closest_zero = np.argmin(np.abs(thresholds))\n",
        "closest_zero_p = precision[closest_zero]\n",
        "closest_zero_r = recall[closest_zero]\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim([0.0, 1.01])\n",
        "plt.ylim([0.0, 1.01])\n",
        "plt.plot(precision, recall, label='Precision-Recall Curve')\n",
        "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
        "plt.xlabel('Precision', fontsize=16)\n",
        "plt.ylabel('Recall', fontsize=16)\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzhMtLiqIwQv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ROC curves, Area-Under-Curve (AUC)"
      ]
    },
    {
      "metadata": {
        "id": "CxD_AHJhIwQw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "\n",
        "y_score_lr = lr.fit(X_train, y_train).decision_function(X_test)\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)\n",
        "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim([-0.01, 1.00])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.plot(fpr_lr, tpr_lr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
        "plt.xlabel('False Positive Rate', fontsize=16)\n",
        "plt.ylabel('True Positive Rate', fontsize=16)\n",
        "plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YxBlaKoOIwQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import cm\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim([-0.01, 1.00])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "for g in [0.01, 0.1, 0.20, 1]:\n",
        "    svm = SVC(gamma=g).fit(X_train, y_train)\n",
        "    y_score_svm = svm.decision_function(X_test)\n",
        "    fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)\n",
        "    roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
        "    accuracy_svm = svm.score(X_test, y_test)\n",
        "    print(\"gamma = {:.2f}  accuracy = {:.2f}   AUC = {:.2f}\".format(g, accuracy_svm, \n",
        "                                                                    roc_auc_svm))\n",
        "    plt.plot(fpr_svm, tpr_svm, lw=3, alpha=0.7, \n",
        "             label='SVM (gamma = {:0.2f}, area = {:0.2f})'.format(g, roc_auc_svm))\n",
        "\n",
        "plt.xlabel('False Positive Rate', fontsize=16)\n",
        "plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
        "plt.plot([0, 1], [0, 1], color='k', lw=0.5, linestyle='--')\n",
        "plt.legend(loc=\"lower right\", fontsize=11)\n",
        "plt.title('ROC curve: (1-of-10 digits classifier)', fontsize=16)\n",
        "plt.axes().set_aspect('equal')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NwzMpu70IwRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Métricas de Evaluación de regresión"
      ]
    },
    {
      "metadata": {
        "id": "DHeYK0SKIwRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "diabetes = datasets.load_diabetes()\n",
        "\n",
        "X = diabetes.data[:, None, 6]\n",
        "y = diabetes.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "lm = LinearRegression().fit(X_train, y_train)\n",
        "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(X_train, y_train)\n",
        "\n",
        "y_predict = lm.predict(X_test)\n",
        "y_predict_dummy_mean = lm_dummy_mean.predict(X_test)\n",
        "\n",
        "print('Linear model, coefficients: ', lm.coef_)\n",
        "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(y_test, \n",
        "                                                                     y_predict_dummy_mean)))\n",
        "print(\"Mean squared error (linear model): {:.2f}\".format(mean_squared_error(y_test, y_predict)))\n",
        "print(\"r2_score (dummy): {:.2f}\".format(r2_score(y_test, y_predict_dummy_mean)))\n",
        "print(\"r2_score (linear model): {:.2f}\".format(r2_score(y_test, y_predict)))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(X_test, y_test,  color='black')\n",
        "plt.plot(X_test, y_predict, color='green', linewidth=2)\n",
        "plt.plot(X_test, y_predict_dummy_mean, color='red', linestyle = 'dashed', \n",
        "         linewidth=2, label = 'dummy')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TQyUvCbEIwRS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Selección de Modelos utilizando métricas de evaluación"
      ]
    },
    {
      "metadata": {
        "id": "7wrx4wfmIwRT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Cross-validation "
      ]
    },
    {
      "metadata": {
        "id": "YWg4rKO2IwRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "dataset = load_digits()\n",
        "# again, making this a binary problem with 'digit 1' as positive class \n",
        "# and 'not 1' as negative class\n",
        "X, y = dataset.data, dataset.target == 1\n",
        "clf = SVC(kernel='linear', C=1)\n",
        "\n",
        "# accuracy is the default scoring metric\n",
        "print('Cross-validation (accuracy)', cross_val_score(clf, X, y, cv=5))\n",
        "# use AUC as scoring metric\n",
        "print('Cross-validation (AUC)', cross_val_score(clf, X, y, cv=5, scoring = 'roc_auc'))\n",
        "# use recall as scoring metric\n",
        "print('Cross-validation (recall)', cross_val_score(clf, X, y, cv=5, scoring = 'recall'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j987xM6HJwHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "S8PcWTbxIwRh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Métricas de evaluación soportadas para selección de modelos"
      ]
    },
    {
      "metadata": {
        "id": "wHHfmOKIIwRi",
        "colab_type": "code",
        "outputId": "5037d1a0-cb9f-40f7-ed24-7840c75f00d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.scorer import SCORERS\n",
        "\n",
        "print(sorted(list(SCORERS.keys())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'brier_score_loss', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}